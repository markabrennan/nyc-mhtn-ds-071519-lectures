{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Off?\n",
    "\n",
    "You are a data scientist for the MTA. For your first project, they want you to predict the number of subway riders for each day. You decide to do a linear regression model predict the riders but need to gather data first. With a partner brainstorm a list of different variables you think would explain the number of daily riders.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "Agenda Today:\n",
    "\n",
    "- Create a model for multiple linear regression\n",
    "- Interpret the output for multiple linear regression\n",
    "- Multicollinearity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a simple linear regression in python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in car data\n",
    "df = sns.load_dataset('mpg')\n",
    "#read in movie data\n",
    "movie_df = pd.read_csv('cleaned_movie_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear regression model using statsmodel \n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "lr_model = ols(formula='mpg~weight', data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year origin                       name  \n",
       "0          70    usa  chevrolet chevelle malibu  \n",
       "1          70    usa          buick skylark 320  \n",
       "2          70    usa         plymouth satellite  \n",
       "3          70    usa              amc rebel sst  \n",
       "4          70    usa                ford torino  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you think the following things are doing.\n",
    "\n",
    "`ols()`\n",
    "\n",
    "`formula = 'mpg~weight`\n",
    "\n",
    "`data=df`\n",
    "\n",
    "`fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.692</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.691</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   888.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>2.97e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:29:57</td>     <th>  Log-Likelihood:    </th> <td> -1148.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   398</td>      <th>  AIC:               </th> <td>   2301.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   396</td>      <th>  BIC:               </th> <td>   2309.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   46.3174</td> <td>    0.795</td> <td>   58.243</td> <td> 0.000</td> <td>   44.754</td> <td>   47.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>    <td>   -0.0077</td> <td>    0.000</td> <td>  -29.814</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>40.423</td> <th>  Durbin-Watson:     </th> <td>   0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  56.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.713</td> <th>  Prob(JB):          </th> <td>4.89e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.176</td> <th>  Cond. No.          </th> <td>1.13e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.13e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.692\n",
       "Model:                            OLS   Adj. R-squared:                  0.691\n",
       "Method:                 Least Squares   F-statistic:                     888.9\n",
       "Date:                Mon, 19 Aug 2019   Prob (F-statistic):          2.97e-103\n",
       "Time:                        11:29:57   Log-Likelihood:                -1148.4\n",
       "No. Observations:                 398   AIC:                             2301.\n",
       "Df Residuals:                     396   BIC:                             2309.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     46.3174      0.795     58.243      0.000      44.754      47.881\n",
       "weight        -0.0077      0.000    -29.814      0.000      -0.008      -0.007\n",
       "==============================================================================\n",
       "Omnibus:                       40.423   Durbin-Watson:                   0.797\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               56.695\n",
       "Skew:                           0.713   Prob(JB):                     4.89e-13\n",
       "Kurtosis:                       4.176   Cond. No.                     1.13e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.13e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "Multiple linear regression is simply a linear regression with more than one predictor, or independent variables. Let's recall the interpretation of $R^2$ in simple linear regression represents the proportion of variance explained by the model. What if we make the model more complex by including more predictors in it such that it account for even more variance in the outcome?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + + \\beta_3 X_3\\cdots + \\beta_k X_k + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "sen = np.random.uniform(18, 65, 100)\n",
    "income = np.random.normal((sen/10), 0.5)\n",
    "sen = sen.reshape(-1,1)\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "fig.suptitle('seniority vs. income', fontsize=16)\n",
    "plt.scatter(sen, income)\n",
    "plt.plot(sen, sen/10, c = \"black\")\n",
    "plt.xlabel(\"seniority\", fontsize=14)\n",
    "plt.ylabel(\"monthly income\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we include another factor, such as years of education? All that is doing is adding a higher dimensional object to the model, so our model will be three dimensional. \n",
    "<img src=\"multi_reg_graph.png\" style=\"withd:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
       "       'acceleration', 'model_year', 'origin', 'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.708</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.704</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   186.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>9.82e-101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:40:25</td>     <th>  Log-Likelihood:    </th> <td> -1120.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2252.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   386</td>      <th>  BIC:               </th> <td>   2276.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   46.2643</td> <td>    2.669</td> <td>   17.331</td> <td> 0.000</td> <td>   41.016</td> <td>   51.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -0.0052</td> <td>    0.001</td> <td>   -6.351</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>   <td>   -0.0453</td> <td>    0.017</td> <td>   -2.716</td> <td> 0.007</td> <td>   -0.078</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displacement</th> <td>-8.313e-05</td> <td>    0.009</td> <td>   -0.009</td> <td> 0.993</td> <td>   -0.018</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cylinders</th>    <td>   -0.3979</td> <td>    0.411</td> <td>   -0.969</td> <td> 0.333</td> <td>   -1.205</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>   -0.0291</td> <td>    0.126</td> <td>   -0.231</td> <td> 0.817</td> <td>   -0.276</td> <td>    0.218</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.561</td> <th>  Durbin-Watson:     </th> <td>   0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  52.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.706</td> <th>  Prob(JB):          </th> <td>3.53e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.111</td> <th>  Cond. No.          </th> <td>3.87e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.87e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.708\n",
       "Model:                            OLS   Adj. R-squared:                  0.704\n",
       "Method:                 Least Squares   F-statistic:                     186.9\n",
       "Date:                Mon, 19 Aug 2019   Prob (F-statistic):          9.82e-101\n",
       "Time:                        11:40:25   Log-Likelihood:                -1120.1\n",
       "No. Observations:                 392   AIC:                             2252.\n",
       "Df Residuals:                     386   BIC:                             2276.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       46.2643      2.669     17.331      0.000      41.016      51.513\n",
       "weight          -0.0052      0.001     -6.351      0.000      -0.007      -0.004\n",
       "horsepower      -0.0453      0.017     -2.716      0.007      -0.078      -0.012\n",
       "displacement -8.313e-05      0.009     -0.009      0.993      -0.018       0.018\n",
       "cylinders       -0.3979      0.411     -0.969      0.333      -1.205       0.409\n",
       "acceleration    -0.0291      0.126     -0.231      0.817      -0.276       0.218\n",
       "==============================================================================\n",
       "Omnibus:                       38.561   Durbin-Watson:                   0.865\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               52.737\n",
       "Skew:                           0.706   Prob(JB):                     3.53e-12\n",
       "Kurtosis:                       4.111   Cond. No.                     3.87e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.87e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_model = ols(formula='mpg~weight+horsepower+displacement+cylinders+acceleration', data=df).fit()\n",
    "mlr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Model Parameters\n",
    "- Each β parameter represents the change in the mean response, E(y), per unit increase in the associated predictor variable when all the other predictors are held constant.\n",
    "- For example, β1 represents the estimated change in the mean response, E(y), per unit increase in x1 when x2, x3, ..., xp−1 are held constant.\n",
    "- The intercept term, β0, represents the estimated mean response, E(y), when all the predictors x1, x2, ..., xp−1, are all zero (which may or may not have any practical meaning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Create a using the code example above create a multiple linear regression model to predict the gross revenue of movies.  \n",
    "\n",
    "***For now, do not put in any categorical variables like movie rating***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>rating</th>\n",
       "      <th>G</th>\n",
       "      <th>Other</th>\n",
       "      <th>PG</th>\n",
       "      <th>PG-13</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>33000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>85000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>164000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Color</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>462.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>Samantha Morton</td>\n",
       "      <td>640.0</td>\n",
       "      <td>73058679.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>24000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "5  Color     Andrew Stanton                   462.0     132.0   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "5                    475.0                   530.0   Samantha Morton   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres ...  \\\n",
       "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi ...   \n",
       "1                 40000.0  309404152.0         Action|Adventure|Fantasy ...   \n",
       "2                 11000.0  200074175.0        Action|Adventure|Thriller ...   \n",
       "3                 27000.0  448130642.0                  Action|Thriller ...   \n",
       "5                   640.0   73058679.0          Action|Adventure|Sci-Fi ...   \n",
       "\n",
       "  title_year actor_2_facebook_likes  imdb_score  movie_facebook_likes rating  \\\n",
       "0     2009.0                  936.0         7.9                 33000  PG-13   \n",
       "1     2007.0                 5000.0         7.1                     0  PG-13   \n",
       "2     2015.0                  393.0         6.8                 85000  PG-13   \n",
       "3     2012.0                23000.0         8.5                164000  PG-13   \n",
       "5     2012.0                  632.0         6.6                 24000  PG-13   \n",
       "\n",
       "   G Other  PG PG-13  R  \n",
       "0  0     0   0     1  0  \n",
       "1  0     0   0     1  0  \n",
       "2  0     0   0     1  0  \n",
       "3  0     0   0     1  0  \n",
       "5  0     0   0     1  0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code here\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n",
       "       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n",
       "       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n",
       "       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n",
       "       'actor_3_name', 'facenumber_in_poster', 'movie_imdb_link',\n",
       "       'num_user_for_reviews', 'language', 'country', 'content_rating',\n",
       "       'budget', 'title_year', 'actor_2_facebook_likes', 'imdb_score',\n",
       "       'movie_facebook_likes', 'rating', 'G', 'Other', 'PG', 'PG-13', 'R'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_model = ols(formula='gross~budget+actor_1_facebook_likes+imdb_score+director_facebook_likes', data=movie_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>gross</td>      <th>  R-squared:         </th> <td>   0.077</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.076</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   86.72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>7.42e-71</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:53:04</td>     <th>  Log-Likelihood:    </th> <td> -80635.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4152</td>      <th>  AIC:               </th> <td>1.613e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4147</td>      <th>  BIC:               </th> <td>1.613e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td> -2.93e+07</td> <td> 6.44e+06</td> <td>   -4.551</td> <td> 0.000</td> <td>-4.19e+07</td> <td>-1.67e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>budget</th>                  <td>    0.0295</td> <td>    0.005</td> <td>    6.221</td> <td> 0.000</td> <td>    0.020</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actor_1_facebook_likes</th>  <td>  584.7916</td> <td>   68.336</td> <td>    8.558</td> <td> 0.000</td> <td>  450.816</td> <td>  718.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>imdb_score</th>              <td>  1.09e+07</td> <td> 9.92e+05</td> <td>   10.980</td> <td> 0.000</td> <td> 8.95e+06</td> <td> 1.28e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>director_facebook_likes</th> <td> 2327.6695</td> <td>  353.770</td> <td>    6.580</td> <td> 0.000</td> <td> 1634.091</td> <td> 3021.248</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2629.038</td> <th>  Durbin-Watson:     </th> <td>   0.918</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>41204.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.775</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>17.400</td>  <th>  Cond. No.          </th> <td>1.40e+09</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  gross   R-squared:                       0.077\n",
       "Model:                            OLS   Adj. R-squared:                  0.076\n",
       "Method:                 Least Squares   F-statistic:                     86.72\n",
       "Date:                Mon, 19 Aug 2019   Prob (F-statistic):           7.42e-71\n",
       "Time:                        11:53:04   Log-Likelihood:                -80635.\n",
       "No. Observations:                4152   AIC:                         1.613e+05\n",
       "Df Residuals:                    4147   BIC:                         1.613e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                -2.93e+07   6.44e+06     -4.551      0.000   -4.19e+07   -1.67e+07\n",
       "budget                      0.0295      0.005      6.221      0.000       0.020       0.039\n",
       "actor_1_facebook_likes    584.7916     68.336      8.558      0.000     450.816     718.767\n",
       "imdb_score                1.09e+07   9.92e+05     10.980      0.000    8.95e+06    1.28e+07\n",
       "director_facebook_likes  2327.6695    353.770      6.580      0.000    1634.091    3021.248\n",
       "==============================================================================\n",
       "Omnibus:                     2629.038   Durbin-Watson:                   0.918\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            41204.150\n",
       "Skew:                           2.775   Prob(JB):                         0.00\n",
       "Kurtosis:                      17.400   Cond. No.                     1.40e+09\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is the Adjusted R-squared?\n",
    "\n",
    "The adjusted R-squared compares the explanatory power of regression models that contain different numbers of predictors.\n",
    "\n",
    "Suppose you compare a five-predictor model with a higher R-squared to a one-predictor model. Does the five predictor model have a higher R-squared because it’s better? Or is the R-squared higher because it has more predictors? Simply compare the adjusted R-squared values to find out!\n",
    "\n",
    "$$Adjusted R^2=1-\\left(\\frac{n-1}{n-p}\\right)(1-R^2)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "n = sample size   \n",
    "\n",
    "p  = the number of independent variables in the regression equation\n",
    "\n",
    "\n",
    "- The adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model. \n",
    "\n",
    "- The adjusted R-squared increases only if the new term improves the model more than would be expected by chance. It decreases when a predictor improves the model by less than expected by chance. \n",
    "\n",
    "- It is always lower than the R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity \n",
    "\n",
    "**Multicollinearity** occurs when independent variables in a regression model are very highly correlated. This correlation is a problem because independent variables should be independent. If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the results.\n",
    "\n",
    "The interpretation of a regression coefficient is that it represents the mean change in the dependent variable for each 1 unit change in an independent variable when you hold all of the other independent variables constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two basic kinds of multicollinearity:\n",
    "\n",
    "- **Structural multicollinearity:** This type occurs when we create a model term using other terms. In other words, it’s a byproduct of the model that we specify rather than being present in the data itself. For example, if you square term X to model curvature, clearly there is a correlation between X and X2.\n",
    "- **Data multicollinearity:** This type of multicollinearity is present in the data itself rather than being an artifact of our model. Observational experiments are more likely to exhibit this kind of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Problems Do Multicollinearity Cause?\n",
    "\n",
    "Multicollinearity causes the following two basic types of problems:\n",
    "\n",
    "- The coefficient estimates can swing wildly based on which other independent variables are in the model. The coefficients become very sensitive to small changes in the model.\n",
    "- Multicollinearity reduces the precision of the estimate coefficients, which weakens the statistical power of your regression model. You might not be able to trust the p-values to identify independent variables that are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do I Have to Fix Multicollinearity?\n",
    "\n",
    "The need to reduce multicollinearity depends on its severity and your primary goal for your regression model. Keep the following three points in mind:\n",
    "\n",
    "- The severity of the problems increases with the degree of the multicollinearity. Therefore, if you have only moderate multicollinearity, you may not need to resolve it.\n",
    "- Multicollinearity affects only the specific independent variables that are correlated. Therefore, if multicollinearity is not present for the independent variables that you are particularly interested in, you may not need to resolve it. \n",
    "- Multicollinearity affects the coefficients and p-values, but it does not influence the predictions, precision of the predictions, and the goodness-of-fit statistics. If your primary goal is to make predictions, and you don’t need to understand the role of each independent variable, you don’t need to reduce severe multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***That being said, the easies way to deal with multicollinearity is just to remove one of the variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(df.corr())\n",
    "plt.xticks(range(len(df.columns)), df.columns)\n",
    "plt.yticks(range(len(df.columns)), df.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Better Looking Heatmap with Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrMtx(df, dropDuplicates = True):\n",
    "\n",
    "    # Your dataset is already a correlation matrix.\n",
    "    # If you have a dateset where you need to include the calculation\n",
    "    # of a correlation matrix, just uncomment the line below:\n",
    "    # df = df.corr()\n",
    "\n",
    "    # Exclude duplicate correlations by masking uper right values\n",
    "    if dropDuplicates:    \n",
    "        mask = np.zeros_like(df, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set background color / chart style\n",
    "    sns.set_style(style = 'white')\n",
    "\n",
    "    # Set up  matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Add diverging colormap from red to blue\n",
    "    cmap = sns.diverging_palette(250, 10, as_cmap=True)\n",
    "\n",
    "    # Draw correlation plot with or without duplicates\n",
    "    if dropDuplicates:\n",
    "        sns.heatmap(df, mask=mask, cmap=cmap, \n",
    "                square=True,\n",
    "                linewidth=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "    else:\n",
    "        sns.heatmap(df, cmap=cmap, \n",
    "                square=True,\n",
    "                linewidth=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "\n",
    "\n",
    "CorrMtx(corr, dropDuplicates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more examples to make your correlation heatmap look good\n",
    "https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun the Model After Removing the highly correlate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_model = ols(formula='mpg~weight+horsepower+cylinders+acceleration', data=df).fit()\n",
    "mlr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Movie Data\n",
    "\n",
    "Identify any variables with a high correlation, remove one of them, and rerun your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## yoru code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Everything about regression:  https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-tutorial-and-examples\n",
    "\n",
    "Statsmodels example: https://datatofish.com/statsmodels-linear-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
